{
  "matchedElements" : [ {
    "left" : "class : SparkLauncher",
    "right" : "class : SparkLauncher",
    "info" : "TypeDeclaration[5560-25569]:TypeDeclaration[5599-25740]"
  }, {
    "left" : "LOG",
    "right" : "LOG",
    "info" : "FieldDeclaration[5658-5728]:FieldDeclaration[5697-5767]"
  }, {
    "left" : "sparkContext",
    "right" : "sparkContext",
    "info" : "FieldDeclaration[5883-5935]:FieldDeclaration[5922-5974]"
  }, {
    "left" : "jobMetricsListener",
    "right" : "jobMetricsListener",
    "info" : "FieldDeclaration[5937-6017]:FieldDeclaration[5976-6056]"
  }, {
    "left" : "jobGroupID",
    "right" : "jobGroupID",
    "info" : "FieldDeclaration[6019-6045]:FieldDeclaration[6058-6084]"
  }, {
    "left" : "pigContext",
    "right" : "pigContext",
    "info" : "FieldDeclaration[6050-6087]:FieldDeclaration[6089-6126]"
  }, {
    "left" : "currentDirectoryPath",
    "right" : "currentDirectoryPath",
    "info" : "FieldDeclaration[6092-6135]:FieldDeclaration[6167-6210]"
  }, {
    "left" : "public launchPig(physicalPlan , grpName , pigContext ) : ",
    "right" : "public launchPig(physicalPlan , grpName , pigContext ) : ",
    "info" : "MethodDeclaration[6138-9287]:MethodDeclaration[6213-9149]"
  }, {
    "left" : "private optimize(pc , plan ) : void",
    "right" : "private optimize(pc , plan ) : void",
    "info" : "MethodDeclaration[9293-9924]:MethodDeclaration[9155-9786]"
  }, {
    "left" : "private getJobIDs(seenJobIDs ...) : ",
    "right" : "private getJobIDs(seenJobIDs ...) : ",
    "info" : "MethodDeclaration[9927-11126]:MethodDeclaration[9789-10988]"
  }, {
    "left" : "private cleanUpSparkJob() : void",
    "right" : "private cleanUpSparkJob() : void",
    "info" : "MethodDeclaration[11129-12235]:MethodDeclaration[10991-12097]"
  }, {
    "left" : "private startSparkJob() : void",
    "right" : "private addFilesToSparkJob() : void",
    "info" : "MethodDeclaration[12238-12562]:MethodDeclaration[12100-12432]"
  }, {
    "left" : "private shipFiles(shipFiles ) : void",
    "right" : "private shipFiles(shipFiles ) : void",
    "info" : "MethodDeclaration[12566-12931]:MethodDeclaration[12436-12801]"
  }, {
    "left" : "private cacheFiles(cacheFiles ) : void",
    "right" : "private cacheFiles(cacheFiles ) : void",
    "info" : "MethodDeclaration[12934-13616]:MethodDeclaration[12804-13486]"
  }, {
    "left" : "private addJarToSparkJobWorkingDirectory(jarFile , jarName ) : void",
    "right" : "private addJarToSparkJobWorkingDirectory(jarFile , jarName ) : void",
    "info" : "MethodDeclaration[13622-14846]:MethodDeclaration[13492-14716]"
  }, {
    "left" : "private extractFileName(cacheFileUrl ) : ",
    "right" : "private extractFileName(cacheFileUrl ) : ",
    "info" : "MethodDeclaration[14849-15240]:MethodDeclaration[14719-15110]"
  }, {
    "left" : "private extractFileUrl(cacheFileUrl ) : ",
    "right" : "private extractFileUrl(cacheFileUrl ) : ",
    "info" : "MethodDeclaration[15243-15633]:MethodDeclaration[15113-15503]"
  }, {
    "left" : "private compile(physicalPlan , pigContext ) : ",
    "right" : "private compile(physicalPlan , pigContext ) : ",
    "info" : "MethodDeclaration[15636-16157]:MethodDeclaration[15506-16027]"
  }, {
    "left" : "private startSparkIfNeeded(pc ) : void",
    "right" : "private startSparkIfNeeded(pc ) : void",
    "info" : "MethodDeclaration[16160-17490]:MethodDeclaration[16030-17360]"
  }, {
    "left" : "package stopSpark() : void",
    "right" : "package stopSpark() : void",
    "info" : "MethodDeclaration[17568-17678]:MethodDeclaration[17438-17548]"
  }, {
    "left" : "private sparkPlanToRDD(sparkPlan , convertMap , sparkStats , jobConf ) : void",
    "right" : "private sparkPlanToRDD(sparkPlan , convertMap , sparkStats , jobConf ) : void",
    "info" : "MethodDeclaration[17681-18567]:MethodDeclaration[17551-18437]"
  }, {
    "left" : "private addUDFJarsToSparkJobWorkingDirectory(leaf ) : void",
    "right" : "private addUDFJarsToSparkJobWorkingDirectory(leaf ) : void",
    "info" : "MethodDeclaration[18573-19077]:MethodDeclaration[18443-18947]"
  }, {
    "left" : "private sparkOperToRDD(sparkPlan , sparkOperator , sparkOpRdds , physicalOpRdds , convertMap , seenJobIDs , sparkStats , conf ) : void",
    "right" : "private sparkOperToRDD(sparkPlan , sparkOperator , sparkOpRdds , physicalOpRdds , convertMap , seenJobIDs , sparkStats , conf ) : void",
    "info" : "MethodDeclaration[19083-21885]:MethodDeclaration[18953-21755]"
  }, {
    "left" : "private physicalToRDD(plan , physicalOperator , rdds , rddsFromPredeSparkOper , convertMap ) : void",
    "right" : "private physicalToRDD(plan , physicalOperator , rdds , rddsFromPredeSparkOper , convertMap ) : void",
    "info" : "MethodDeclaration[21888-23478]:MethodDeclaration[21758-23348]"
  }, {
    "left" : "public explain(pp , pc , ps , format , verbose boolean) : void",
    "right" : "public explain(pp , pc , ps , format , verbose boolean) : void",
    "info" : "MethodDeclaration[23481-23706]:MethodDeclaration[23351-23576]"
  }, {
    "left" : "private explain(sparkPlan , ps , format , verbose boolean) : void",
    "right" : "private explain(sparkPlan , ps , format , verbose boolean) : void",
    "info" : "MethodDeclaration[23709-24661]:MethodDeclaration[23579-24531]"
  }, {
    "left" : "public kill() : void",
    "right" : "public kill() : void",
    "info" : "MethodDeclaration[24664-24760]:MethodDeclaration[24534-24630]"
  }, {
    "left" : "public killJob(jobID , conf ) : void",
    "right" : "public killJob(jobID , conf ) : void",
    "info" : "MethodDeclaration[24763-24897]:MethodDeclaration[24633-24767]"
  }, {
    "left" : "private saveUdfImportList(pigContext ) : void",
    "right" : "private saveUdfImportList() : void",
    "info" : "MethodDeclaration[24903-25567]:MethodDeclaration[24773-25391]"
  } ],
  "mappings" : [ {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[6261-9287]:Block[6336-9149]"
  }, {
    "left" : "if (LOG.isDebugEnabled())",
    "right" : "if (LOG.isDebugEnabled())",
    "info" : "IfStatement[6265-6321]:IfStatement[6340-6396]"
  }, {
    "left" : "LOG.debug(physicalPlan);",
    "right" : "LOG.debug(physicalPlan);",
    "info" : "ExpressionStatement[6297-6321]:ExpressionStatement[6372-6396]"
  }, {
    "left" : "this.pigContext = pigContext;",
    "right" : "this.pigContext = pigContext;",
    "info" : "ExpressionStatement[6330-6359]:ExpressionStatement[6405-6434]"
  }, {
    "left" : "saveUdfImportList(pigContext);",
    "right" : "saveUdfImportList();",
    "info" : "ExpressionStatement[6368-6398]:ExpressionStatement[25452-25472]"
  }, {
    "left" : "jobConf",
    "right" : "jobConf",
    "info" : "SimpleName[6409-6416]:SimpleName[25481-25488]"
  }, {
    "left" : "SparkUtil.newJobConf(pigContext)",
    "right" : "SparkUtil.newJobConf(pigContext)",
    "info" : "MethodInvocation[6419-6451]:MethodInvocation[25491-25523]"
  }, {
    "left" : "jobConf.set(PigConstants.LOCAL_CODE_DIR,\n\t\t\t\tSystem.getProperty(\"java.io.tmpdir\"));",
    "right" : "jobConf.set(PigConstants.LOCAL_CODE_DIR,\n                System.getProperty(\"java.io.tmpdir\"));",
    "info" : "ExpressionStatement[6455-6538]:ExpressionStatement[25533-25628]"
  }, {
    "left" : "SchemaTupleBackend.initialize(jobConf, pigContext);",
    "right" : "SchemaTupleBackend.initialize(jobConf, pigContext);",
    "info" : "ExpressionStatement[6542-6593]:ExpressionStatement[25638-25689]"
  }, {
    "left" : "SparkOperPlan sparkplan = compile(physicalPlan, pigContext);",
    "right" : "SparkOperPlan sparkplan = compile(physicalPlan, pigContext);",
    "info" : "VariableDeclarationStatement[6596-6656]:VariableDeclarationStatement[6453-6513]"
  }, {
    "left" : "if (LOG.isDebugEnabled())",
    "right" : "if (LOG.isDebugEnabled())",
    "info" : "IfStatement[6659-6735]:IfStatement[6516-6592]"
  }, {
    "left" : "explain(sparkplan, System.out, \"text\", true);",
    "right" : "explain(sparkplan, System.out, \"text\", true);",
    "info" : "ExpressionStatement[6690-6735]:ExpressionStatement[6547-6592]"
  }, {
    "left" : "SparkPigStats sparkStats = (SparkPigStats) pigContext\n\t\t\t\t.getExecutionEngine().instantiatePigStats();",
    "right" : "SparkPigStats sparkStats = (SparkPigStats) pigContext\n\t\t\t\t.getExecutionEngine().instantiatePigStats();",
    "info" : "VariableDeclarationStatement[6738-6840]:VariableDeclarationStatement[6595-6697]"
  }, {
    "left" : "PigStats.start(sparkStats);",
    "right" : "PigStats.start(sparkStats);",
    "info" : "ExpressionStatement[6843-6870]:ExpressionStatement[6700-6727]"
  }, {
    "left" : "startSparkIfNeeded(pigContext);",
    "right" : "startSparkIfNeeded(pigContext);",
    "info" : "ExpressionStatement[6874-6905]:ExpressionStatement[6731-6762]"
  }, {
    "left" : "jobGroupID = UUID.randomUUID().toString();",
    "right" : "jobGroupID = UUID.randomUUID().toString();",
    "info" : "ExpressionStatement[7020-7062]:ExpressionStatement[6877-6919]"
  }, {
    "left" : "sparkContext.setJobGroup(jobGroupID, \"Pig query to Spark cluster\",\n\t\t\t\tfalse);",
    "right" : "sparkContext.setJobGroup(jobGroupID, \"Pig query to Spark cluster\",\n\t\t\t\tfalse);",
    "info" : "ExpressionStatement[7065-7143]:ExpressionStatement[6922-7000]"
  }, {
    "left" : "jobMetricsListener.reset();",
    "right" : "jobMetricsListener.reset();",
    "info" : "ExpressionStatement[7146-7173]:ExpressionStatement[7003-7030]"
  }, {
    "left" : "this.currentDirectoryPath = Paths.get(\".\").toAbsolutePath()\n\t\t\t\t.normalize().toString()\n\t\t\t\t+ \"/\";",
    "right" : "this.currentDirectoryPath = Paths.get(\".\").toAbsolutePath()\n\t\t\t\t.normalize().toString()\n\t\t\t\t+ \"/\";",
    "info" : "ExpressionStatement[7177-7275]:ExpressionStatement[7034-7132]"
  }, {
    "left" : "LinkedList<POStore> stores = PlanHelper.getPhysicalOperators(\n\t\t\t\tphysicalPlan, POStore.class);",
    "right" : "LinkedList<POStore> stores = PlanHelper.getPhysicalOperators(\n\t\t\t\tphysicalPlan, POStore.class);",
    "info" : "VariableDeclarationStatement[7297-7392]:VariableDeclarationStatement[7159-7254]"
  }, {
    "left" : "POStore firstStore = stores.getFirst();",
    "right" : "POStore firstStore = stores.getFirst();",
    "info" : "VariableDeclarationStatement[7395-7434]:VariableDeclarationStatement[7257-7296]"
  }, {
    "left" : "if (firstStore != null)",
    "right" : "if (firstStore != null)",
    "info" : "IfStatement[7437-7548]:IfStatement[7299-7410]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[7461-7548]:Block[7323-7410]"
  }, {
    "left" : "MapRedUtil.setupStreamingDirsConfSingle(firstStore, pigContext,\n\t\t\t\t\tjobConf);",
    "right" : "MapRedUtil.setupStreamingDirsConfSingle(firstStore, pigContext,\n\t\t\t\t\tjobConf);",
    "info" : "ExpressionStatement[7466-7544]:ExpressionStatement[7328-7406]"
  }, {
    "left" : "new ParallelismSetter(sparkplan, jobConf).visit();",
    "right" : "new ParallelismSetter(sparkplan, jobConf).visit();",
    "info" : "ExpressionStatement[7552-7602]:ExpressionStatement[7414-7464]"
  }, {
    "left" : "byte[] confBytes = KryoSerializer.serializeJobConf(jobConf);",
    "right" : "byte[] confBytes = KryoSerializer.serializeJobConf(jobConf);",
    "info" : "VariableDeclarationStatement[7606-7666]:VariableDeclarationStatement[7468-7528]"
  }, {
    "left" : "Map<Class<? extends PhysicalOperator>, RDDConverter> convertMap\n\t\t\t\t= new HashMap<Class<? extends PhysicalOperator>, RDDConverter>();",
    "right" : "Map<Class<? extends PhysicalOperator>, RDDConverter> convertMap\n\t\t\t\t= new HashMap<Class<? extends PhysicalOperator>, RDDConverter>();",
    "info" : "VariableDeclarationStatement[7747-7880]:VariableDeclarationStatement[7609-7742]"
  }, {
    "left" : "convertMap.put(POLoad.class, new LoadConverter(pigContext,\n\t\t\t\tphysicalPlan, sparkContext.sc()));",
    "right" : "convertMap.put(POLoad.class, new LoadConverter(pigContext,\n\t\t\t\tphysicalPlan, sparkContext.sc()));",
    "info" : "ExpressionStatement[7883-7980]:ExpressionStatement[7745-7842]"
  }, {
    "left" : "convertMap.put(POStore.class, new StoreConverter(pigContext));",
    "right" : "convertMap.put(POStore.class, new StoreConverter(pigContext));",
    "info" : "ExpressionStatement[7983-8045]:ExpressionStatement[7845-7907]"
  }, {
    "left" : "convertMap.put(POForEach.class, new ForEachConverter(confBytes));",
    "right" : "convertMap.put(POForEach.class, new ForEachConverter(confBytes));",
    "info" : "ExpressionStatement[8048-8113]:ExpressionStatement[7910-7975]"
  }, {
    "left" : "convertMap.put(POFilter.class, new FilterConverter());",
    "right" : "convertMap.put(POFilter.class, new FilterConverter());",
    "info" : "ExpressionStatement[8116-8170]:ExpressionStatement[7978-8032]"
  }, {
    "left" : "convertMap.put(POPackage.class, new PackageConverter(confBytes));",
    "right" : "convertMap.put(POPackage.class, new PackageConverter(confBytes));",
    "info" : "ExpressionStatement[8173-8238]:ExpressionStatement[8035-8100]"
  }, {
    "left" : "convertMap.put(POLocalRearrange.class, new LocalRearrangeConverter());",
    "right" : "convertMap.put(POLocalRearrange.class, new LocalRearrangeConverter());",
    "info" : "ExpressionStatement[8241-8311]:ExpressionStatement[8103-8173]"
  }, {
    "left" : "convertMap.put(POGlobalRearrangeSpark.class, new GlobalRearrangeConverter());",
    "right" : "convertMap.put(POGlobalRearrangeSpark.class, new GlobalRearrangeConverter());",
    "info" : "ExpressionStatement[8320-8397]:ExpressionStatement[8182-8259]"
  }, {
    "left" : "convertMap.put(POLimit.class, new LimitConverter());",
    "right" : "convertMap.put(POLimit.class, new LimitConverter());",
    "info" : "ExpressionStatement[8406-8458]:ExpressionStatement[8268-8320]"
  }, {
    "left" : "convertMap.put(PODistinct.class, new DistinctConverter());",
    "right" : "convertMap.put(PODistinct.class, new DistinctConverter());",
    "info" : "ExpressionStatement[8467-8525]:ExpressionStatement[8329-8387]"
  }, {
    "left" : "convertMap.put(POUnion.class, new UnionConverter(sparkContext.sc()));",
    "right" : "convertMap.put(POUnion.class, new UnionConverter(sparkContext.sc()));",
    "info" : "ExpressionStatement[8528-8597]:ExpressionStatement[8390-8459]"
  }, {
    "left" : "convertMap.put(POSort.class, new SortConverter());",
    "right" : "convertMap.put(POSort.class, new SortConverter());",
    "info" : "ExpressionStatement[8600-8650]:ExpressionStatement[8462-8512]"
  }, {
    "left" : "convertMap.put(POSplit.class, new SplitConverter());",
    "right" : "convertMap.put(POSplit.class, new SplitConverter());",
    "info" : "ExpressionStatement[8653-8705]:ExpressionStatement[8515-8567]"
  }, {
    "left" : "convertMap.put(POSkewedJoin.class, new SkewedJoinConverter());",
    "right" : "convertMap.put(POSkewedJoin.class, new SkewedJoinConverter());",
    "info" : "ExpressionStatement[8708-8770]:ExpressionStatement[8570-8632]"
  }, {
    "left" : "convertMap.put(POMergeJoin.class, new MergeJoinConverter());",
    "right" : "convertMap.put(POMergeJoin.class, new MergeJoinConverter());",
    "info" : "ExpressionStatement[8773-8833]:ExpressionStatement[8635-8695]"
  }, {
    "left" : "convertMap.put(POCollectedGroup.class, new CollectedGroupConverter());",
    "right" : "convertMap.put(POCollectedGroup.class, new CollectedGroupConverter());",
    "info" : "ExpressionStatement[8836-8906]:ExpressionStatement[8698-8768]"
  }, {
    "left" : "convertMap.put(POCounter.class, new CounterConverter());",
    "right" : "convertMap.put(POCounter.class, new CounterConverter());",
    "info" : "ExpressionStatement[8909-8965]:ExpressionStatement[8771-8827]"
  }, {
    "left" : "convertMap.put(PORank.class, new RankConverter());",
    "right" : "convertMap.put(PORank.class, new RankConverter());",
    "info" : "ExpressionStatement[8968-9018]:ExpressionStatement[8830-8880]"
  }, {
    "left" : "convertMap.put(POStream.class, new StreamConverter(confBytes));",
    "right" : "convertMap.put(POStream.class, new StreamConverter(confBytes));",
    "info" : "ExpressionStatement[9021-9084]:ExpressionStatement[8883-8946]"
  }, {
    "left" : "convertMap.put(POFRJoin.class, new FRJoinConverter());",
    "right" : "convertMap.put(POFRJoin.class, new FRJoinConverter());",
    "info" : "ExpressionStatement[9101-9155]:ExpressionStatement[8963-9017]"
  }, {
    "left" : "sparkPlanToRDD(sparkplan, convertMap, sparkStats, jobConf);",
    "right" : "sparkPlanToRDD(sparkplan, convertMap, sparkStats, jobConf);",
    "info" : "ExpressionStatement[9159-9218]:ExpressionStatement[9021-9080]"
  }, {
    "left" : "cleanUpSparkJob();",
    "right" : "cleanUpSparkJob();",
    "info" : "ExpressionStatement[9221-9239]:ExpressionStatement[9083-9101]"
  }, {
    "left" : "sparkStats.finish();",
    "right" : "sparkStats.finish();",
    "info" : "ExpressionStatement[9242-9262]:ExpressionStatement[9104-9124]"
  }, {
    "left" : "return sparkStats;",
    "right" : "return sparkStats;",
    "info" : "ReturnStatement[9266-9284]:ReturnStatement[9128-9146]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[9374-9924]:Block[9236-9786]"
  }, {
    "left" : "String prop = pc.getProperties().getProperty(PigConfiguration.PIG_EXEC_NO_SECONDARY_KEY);",
    "right" : "String prop = pc.getProperties().getProperty(PigConfiguration.PIG_EXEC_NO_SECONDARY_KEY);",
    "info" : "VariableDeclarationStatement[9384-9473]:VariableDeclarationStatement[9246-9335]"
  }, {
    "left" : "if (!pc.inIllustrator && !(\"true\".equals(prop)))",
    "right" : "if (!pc.inIllustrator && !(\"true\".equals(prop)))",
    "info" : "IfStatement[9482-9666]:IfStatement[9344-9528]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[9531-9666]:Block[9393-9528]"
  }, {
    "left" : "SecondaryKeyOptimizerSpark skOptimizer = new SecondaryKeyOptimizerSpark(plan);",
    "right" : "SecondaryKeyOptimizerSpark skOptimizer = new SecondaryKeyOptimizerSpark(plan);",
    "info" : "VariableDeclarationStatement[9545-9623]:VariableDeclarationStatement[9407-9485]"
  }, {
    "left" : "skOptimizer.visit();",
    "right" : "skOptimizer.visit();",
    "info" : "ExpressionStatement[9636-9656]:ExpressionStatement[9498-9518]"
  }, {
    "left" : "boolean isAccum =\n                Boolean.valueOf(pc.getProperties().getProperty(\"opt.accumulator\", \"true\"));",
    "right" : "boolean isAccum =\n                Boolean.valueOf(pc.getProperties().getProperty(\"opt.accumulator\", \"true\"));",
    "info" : "VariableDeclarationStatement[9676-9785]:VariableDeclarationStatement[9538-9647]"
  }, {
    "left" : "if (isAccum)",
    "right" : "if (isAccum)",
    "info" : "IfStatement[9794-9918]:IfStatement[9656-9780]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[9807-9918]:Block[9669-9780]"
  }, {
    "left" : "AccumulatorOptimizer accum = new AccumulatorOptimizer(plan);",
    "right" : "AccumulatorOptimizer accum = new AccumulatorOptimizer(plan);",
    "info" : "VariableDeclarationStatement[9821-9881]:VariableDeclarationStatement[9683-9743]"
  }, {
    "left" : "accum.visit();",
    "right" : "accum.visit();",
    "info" : "ExpressionStatement[9894-9908]:ExpressionStatement[9756-9770]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[10610-11126]:Block[10472-10988]"
  }, {
    "left" : "Set<Integer> groupjobIDs = new HashSet<Integer>(\n\t\t\t\tArrays.asList(ArrayUtils.toObject(sparkContext.statusTracker()\n\t\t\t\t\t\t.getJobIdsForGroup(jobGroupID))));",
    "right" : "Set<Integer> groupjobIDs = new HashSet<Integer>(\n\t\t\t\tArrays.asList(ArrayUtils.toObject(sparkContext.statusTracker()\n\t\t\t\t\t\t.getJobIdsForGroup(jobGroupID))));",
    "info" : "VariableDeclarationStatement[10614-10770]:VariableDeclarationStatement[10476-10632]"
  }, {
    "left" : "groupjobIDs.removeAll(seenJobIDs);",
    "right" : "groupjobIDs.removeAll(seenJobIDs);",
    "info" : "ExpressionStatement[10773-10807]:ExpressionStatement[10635-10669]"
  }, {
    "left" : "List<Integer> unseenJobIDs = new ArrayList<Integer>(groupjobIDs);",
    "right" : "List<Integer> unseenJobIDs = new ArrayList<Integer>(groupjobIDs);",
    "info" : "VariableDeclarationStatement[10810-10875]:VariableDeclarationStatement[10672-10737]"
  }, {
    "left" : "if (unseenJobIDs.size() == 0)",
    "right" : "if (unseenJobIDs.size() == 0)",
    "info" : "IfStatement[10878-11064]:IfStatement[10740-10926]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[10908-11064]:Block[10770-10926]"
  }, {
    "left" : "throw new RuntimeException(\"Expected at least one unseen jobID \"\n\t\t\t\t\t+ \" in this call to getJobIdsForGroup, but got \"\n\t\t\t\t\t+ unseenJobIDs.size());",
    "right" : "throw new RuntimeException(\"Expected at least one unseen jobID \"\n\t\t\t\t\t+ \" in this call to getJobIdsForGroup, but got \"\n\t\t\t\t\t+ unseenJobIDs.size());",
    "info" : "ThrowStatement[10913-11060]:ThrowStatement[10775-10922]"
  }, {
    "left" : "seenJobIDs.addAll(unseenJobIDs);",
    "right" : "seenJobIDs.addAll(unseenJobIDs);",
    "info" : "ExpressionStatement[11068-11100]:ExpressionStatement[10930-10962]"
  }, {
    "left" : "return unseenJobIDs;",
    "right" : "return unseenJobIDs;",
    "info" : "ReturnStatement[11103-11123]:ReturnStatement[10965-10985]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[11160-12235]:Block[11022-12097]"
  }, {
    "left" : "LOG.info(\"clean up Spark Job\");",
    "right" : "LOG.info(\"clean up Spark Job\");",
    "info" : "ExpressionStatement[11164-11195]:ExpressionStatement[11026-11057]"
  }, {
    "left" : "boolean isLocal = System.getenv(\"SPARK_MASTER\") != null ? System\n\t\t\t\t.getenv(\"SPARK_MASTER\").equalsIgnoreCase(\"LOCAL\") : true;",
    "right" : "boolean isLocal = System.getenv(\"SPARK_MASTER\") != null ? System\n\t\t\t\t.getenv(\"SPARK_MASTER\").equalsIgnoreCase(\"LOCAL\") : true;",
    "info" : "VariableDeclarationStatement[11198-11324]:VariableDeclarationStatement[11060-11186]"
  }, {
    "left" : "if (isLocal)",
    "right" : "if (isLocal)",
    "info" : "IfStatement[11327-12232]:IfStatement[11189-12094]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[11340-12232]:Block[11202-12094]"
  }, {
    "left" : "String shipFiles = pigContext.getProperties().getProperty(\n\t\t\t\t\t\"pig.streaming.ship.files\");",
    "right" : "String shipFiles = pigContext.getProperties().getProperty(\n\t\t\t\t\t\"pig.streaming.ship.files\");",
    "info" : "VariableDeclarationStatement[11345-11437]:VariableDeclarationStatement[11207-11299]"
  }, {
    "left" : "if (shipFiles != null)",
    "right" : "if (shipFiles != null)",
    "info" : "IfStatement[11441-11779]:IfStatement[11303-11641]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[11464-11779]:Block[11326-11641]"
  }, {
    "left" : "for (String file : shipFiles.split(\",\"))",
    "right" : "for (String file : shipFiles.split(\",\"))",
    "info" : "EnhancedForStatement[11470-11774]:EnhancedForStatement[11332-11636]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[11511-11774]:Block[11373-11636]"
  }, {
    "left" : "File shipFile = new File(file);",
    "right" : "File shipFile = new File(file);",
    "info" : "VariableDeclarationStatement[11518-11549]:VariableDeclarationStatement[11380-11411]"
  }, {
    "left" : "File deleteFile = new File(currentDirectoryPath + \"/\"\n\t\t\t\t\t\t\t+ shipFile.getName());",
    "right" : "File deleteFile = new File(currentDirectoryPath + \"/\"\n\t\t\t\t\t\t\t+ shipFile.getName());",
    "info" : "VariableDeclarationStatement[11555-11638]:VariableDeclarationStatement[11417-11500]"
  }, {
    "left" : "if (deleteFile.exists())",
    "right" : "if (deleteFile.exists())",
    "info" : "IfStatement[11644-11768]:IfStatement[11506-11630]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[11669-11768]:Block[11531-11630]"
  }, {
    "left" : "LOG.info(String.format(\"delete ship file result: %b\",\n\t\t\t\t\t\t\t\tdeleteFile.delete()));",
    "right" : "LOG.info(String.format(\"delete ship file result: %b\",\n\t\t\t\t\t\t\t\tdeleteFile.delete()));",
    "info" : "ExpressionStatement[11677-11761]:ExpressionStatement[11539-11623]"
  }, {
    "left" : "String cacheFiles = pigContext.getProperties().getProperty(\n\t\t\t\t\t\"pig.streaming.cache.files\");",
    "right" : "String cacheFiles = pigContext.getProperties().getProperty(\n\t\t\t\t\t\"pig.streaming.cache.files\");",
    "info" : "VariableDeclarationStatement[11783-11877]:VariableDeclarationStatement[11645-11739]"
  }, {
    "left" : "if (cacheFiles != null)",
    "right" : "if (cacheFiles != null)",
    "info" : "IfStatement[11881-12228]:IfStatement[11743-12090]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[11905-12228]:Block[11767-12090]"
  }, {
    "left" : "for (String file : cacheFiles.split(\",\"))",
    "right" : "for (String file : cacheFiles.split(\",\"))",
    "info" : "EnhancedForStatement[11911-12223]:EnhancedForStatement[11773-12085]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[11953-12223]:Block[11815-12085]"
  }, {
    "left" : "String fileName = extractFileName(file.trim());",
    "right" : "String fileName = extractFileName(file.trim());",
    "info" : "VariableDeclarationStatement[11960-12007]:VariableDeclarationStatement[11822-11869]"
  }, {
    "left" : "File deleteFile = new File(currentDirectoryPath + \"/\"\n\t\t\t\t\t\t\t+ fileName);",
    "right" : "File deleteFile = new File(currentDirectoryPath + \"/\"\n\t\t\t\t\t\t\t+ fileName);",
    "info" : "VariableDeclarationStatement[12013-12086]:VariableDeclarationStatement[11875-11948]"
  }, {
    "left" : "if (deleteFile.exists())",
    "right" : "if (deleteFile.exists())",
    "info" : "IfStatement[12092-12217]:IfStatement[11954-12079]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[12117-12217]:Block[11979-12079]"
  }, {
    "left" : "LOG.info(String.format(\"delete cache file result: %b\",\n\t\t\t\t\t\t\t\tdeleteFile.delete()));",
    "right" : "LOG.info(String.format(\"delete cache file result: %b\",\n\t\t\t\t\t\t\t\tdeleteFile.delete()));",
    "info" : "ExpressionStatement[12125-12210]:ExpressionStatement[11987-12072]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[12286-12562]:Block[12153-12432]"
  }, {
    "left" : "LOG.info(\"start Spark Job\");",
    "right" : "LOG.info(\"add Files Spark Job\");",
    "info" : "ExpressionStatement[12290-12318]:ExpressionStatement[12157-12189]"
  }, {
    "left" : "String shipFiles = pigContext.getProperties().getProperty(\n\t\t\t\t\"pig.streaming.ship.files\");",
    "right" : "String shipFiles = pigContext.getProperties().getProperty(\n\t\t\t\t\"pig.streaming.ship.files\");",
    "info" : "VariableDeclarationStatement[12321-12412]:VariableDeclarationStatement[12192-12283]"
  }, {
    "left" : "shipFiles(shipFiles);",
    "right" : "shipFiles(shipFiles);",
    "info" : "ExpressionStatement[12415-12436]:ExpressionStatement[12286-12307]"
  }, {
    "left" : "String cacheFiles = pigContext.getProperties().getProperty(\n\t\t\t\t\"pig.streaming.cache.files\");",
    "right" : "String cacheFiles = pigContext.getProperties().getProperty(\n\t\t\t\t\"pig.streaming.cache.files\");",
    "info" : "VariableDeclarationStatement[12439-12532]:VariableDeclarationStatement[12310-12403]"
  }, {
    "left" : "cacheFiles(cacheFiles);",
    "right" : "cacheFiles(cacheFiles);",
    "info" : "ExpressionStatement[12535-12558]:ExpressionStatement[12406-12429]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[12629-12931]:Block[12499-12801]"
  }, {
    "left" : "if (shipFiles != null)",
    "right" : "if (shipFiles != null)",
    "info" : "IfStatement[12633-12928]:IfStatement[12503-12798]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[12656-12928]:Block[12526-12798]"
  }, {
    "left" : "for (String file : shipFiles.split(\",\"))",
    "right" : "for (String file : shipFiles.split(\",\"))",
    "info" : "EnhancedForStatement[12661-12924]:EnhancedForStatement[12531-12794]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[12702-12924]:Block[12572-12794]"
  }, {
    "left" : "File shipFile = new File(file.trim());",
    "right" : "File shipFile = new File(file.trim());",
    "info" : "VariableDeclarationStatement[12708-12746]:VariableDeclarationStatement[12578-12616]"
  }, {
    "left" : "if (shipFile.exists())",
    "right" : "if (shipFile.exists())",
    "info" : "IfStatement[12751-12919]:IfStatement[12621-12789]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[12774-12919]:Block[12644-12789]"
  }, {
    "left" : "LOG.info(String.format(\"shipFile:%s\", shipFile));",
    "right" : "LOG.info(String.format(\"shipFile:%s\", shipFile));",
    "info" : "ExpressionStatement[12781-12830]:ExpressionStatement[12651-12700]"
  }, {
    "left" : "addJarToSparkJobWorkingDirectory(shipFile,shipFile.getName());",
    "right" : "addJarToSparkJobWorkingDirectory(shipFile,shipFile.getName());",
    "info" : "ExpressionStatement[12851-12913]:ExpressionStatement[12721-12783]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[12996-13616]:Block[12866-13486]"
  }, {
    "left" : "if (cacheFiles != null)",
    "right" : "if (cacheFiles != null)",
    "info" : "IfStatement[13000-13613]:IfStatement[12870-13483]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[13024-13613]:Block[12894-13483]"
  }, {
    "left" : "Configuration conf = SparkUtil.newJobConf(pigContext);",
    "right" : "Configuration conf = SparkUtil.newJobConf(pigContext);",
    "info" : "VariableDeclarationStatement[13029-13083]:VariableDeclarationStatement[12899-12953]"
  }, {
    "left" : "for (String file : cacheFiles.split(\",\"))",
    "right" : "for (String file : cacheFiles.split(\",\"))",
    "info" : "EnhancedForStatement[13087-13609]:EnhancedForStatement[12957-13479]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[13129-13609]:Block[12999-13479]"
  }, {
    "left" : "String fileName = extractFileName(file.trim());",
    "right" : "String fileName = extractFileName(file.trim());",
    "info" : "VariableDeclarationStatement[13135-13182]:VariableDeclarationStatement[13005-13052]"
  }, {
    "left" : "Path src = new Path(extractFileUrl(file.trim()));",
    "right" : "Path src = new Path(extractFileUrl(file.trim()));",
    "info" : "VariableDeclarationStatement[13187-13236]:VariableDeclarationStatement[13057-13106]"
  }, {
    "left" : "File tmpFile = File.createTempFile(fileName, \".tmp\");",
    "right" : "File tmpFile = File.createTempFile(fileName, \".tmp\");",
    "info" : "VariableDeclarationStatement[13241-13294]:VariableDeclarationStatement[13111-13164]"
  }, {
    "left" : "Path tmpFilePath = new Path(tmpFile.getAbsolutePath());",
    "right" : "Path tmpFilePath = new Path(tmpFile.getAbsolutePath());",
    "info" : "VariableDeclarationStatement[13299-13354]:VariableDeclarationStatement[13169-13224]"
  }, {
    "left" : "FileSystem fs = tmpFilePath.getFileSystem(conf);",
    "right" : "FileSystem fs = tmpFilePath.getFileSystem(conf);",
    "info" : "VariableDeclarationStatement[13359-13407]:VariableDeclarationStatement[13229-13277]"
  }, {
    "left" : "fs.copyToLocalFile(src, tmpFilePath);",
    "right" : "fs.copyToLocalFile(src, tmpFilePath);",
    "info" : "ExpressionStatement[13412-13449]:ExpressionStatement[13282-13319]"
  }, {
    "left" : "tmpFile.deleteOnExit();",
    "right" : "tmpFile.deleteOnExit();",
    "info" : "ExpressionStatement[13454-13477]:ExpressionStatement[13324-13347]"
  }, {
    "left" : "LOG.info(String.format(\"cacheFile:%s\", fileName));",
    "right" : "LOG.info(String.format(\"cacheFile:%s\", fileName));",
    "info" : "ExpressionStatement[13494-13544]:ExpressionStatement[13364-13414]"
  }, {
    "left" : "addJarToSparkJobWorkingDirectory(tmpFile, fileName);",
    "right" : "addJarToSparkJobWorkingDirectory(tmpFile, fileName);",
    "info" : "ExpressionStatement[13552-13604]:ExpressionStatement[13422-13474]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[13717-14846]:Block[13587-14716]"
  }, {
    "left" : "LOG.info(\"Added jar \"+jarName);",
    "right" : "LOG.info(\"Added jar \"+jarName);",
    "info" : "ExpressionStatement[13727-13758]:ExpressionStatement[13597-13628]"
  }, {
    "left" : "boolean isLocal = System.getenv(\"SPARK_MASTER\") != null ? System\n                .getenv(\"SPARK_MASTER\").equalsIgnoreCase(\"LOCAL\") : true;",
    "right" : "boolean isLocal = System.getenv(\"SPARK_MASTER\") != null ? System\n                .getenv(\"SPARK_MASTER\").equalsIgnoreCase(\"LOCAL\") : true;",
    "info" : "VariableDeclarationStatement[13767-13905]:VariableDeclarationStatement[13637-13775]"
  }, {
    "left" : "if (isLocal)",
    "right" : "if (isLocal)",
    "info" : "IfStatement[13914-14840]:IfStatement[13784-14710]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[13927-14726]:Block[13797-14596]"
  }, {
    "left" : "File localFile = new File(currentDirectoryPath + \"/\"\n                    + jarName);",
    "right" : "File localFile = new File(currentDirectoryPath + \"/\"\n                    + jarName);",
    "info" : "VariableDeclarationStatement[13941-14025]:VariableDeclarationStatement[13811-13895]"
  }, {
    "left" : "if (jarFile.getAbsolutePath().equals(localFile.getAbsolutePath()) \n                    && jarFile.exists())",
    "right" : "if (jarFile.getAbsolutePath().equals(localFile.getAbsolutePath()) \n                    && jarFile.exists())",
    "info" : "IfStatement[14038-14185]:IfStatement[13908-14055]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[14146-14185]:Block[14016-14055]"
  }, {
    "left" : "return;",
    "right" : "return;",
    "info" : "ReturnStatement[14164-14171]:ReturnStatement[14034-14041]"
  }, {
    "left" : "if (localFile.exists())",
    "right" : "if (localFile.exists())",
    "info" : "IfStatement[14198-14573]:IfStatement[14068-14443]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[14222-14431]:Block[14092-14301]"
  }, {
    "left" : "LOG.info(String.format(\n                        \"jar file %s exists, ready to delete\",\n                        localFile.getAbsolutePath()));",
    "right" : "LOG.info(String.format(\n                        \"jar file %s exists, ready to delete\",\n                        localFile.getAbsolutePath()));",
    "info" : "ExpressionStatement[14240-14381]:ExpressionStatement[14110-14251]"
  }, {
    "left" : "localFile.delete();",
    "right" : "localFile.delete();",
    "info" : "ExpressionStatement[14398-14417]:ExpressionStatement[14268-14287]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[14437-14573]:Block[14307-14443]"
  }, {
    "left" : "LOG.info(String.format(\"jar file %s not exists,\",\n                        localFile.getAbsolutePath()));",
    "right" : "LOG.info(String.format(\"jar file %s not exists,\",\n                        localFile.getAbsolutePath()));",
    "info" : "ExpressionStatement[14455-14559]:ExpressionStatement[14325-14429]"
  }, {
    "left" : "Files.copy(Paths.get(new Path(jarFile.getAbsolutePath()).toString()),\n                    Paths.get(localFile.getAbsolutePath()));",
    "right" : "Files.copy(Paths.get(new Path(jarFile.getAbsolutePath()).toString()),\n                    Paths.get(localFile.getAbsolutePath()));",
    "info" : "ExpressionStatement[14586-14716]:ExpressionStatement[14456-14586]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[14732-14840]:Block[14602-14710]"
  }, {
    "left" : "sparkContext.addFile(jarFile.toURI().toURL()\n                    .toExternalForm());",
    "right" : "sparkContext.addFile(jarFile.toURI().toURL()\n                    .toExternalForm());",
    "info" : "ExpressionStatement[14746-14830]:ExpressionStatement[14616-14700]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[14901-15240]:Block[14771-15110]"
  }, {
    "left" : "String[] tmpAry = cacheFileUrl.split(\"#\");",
    "right" : "String[] tmpAry = cacheFileUrl.split(\"#\");",
    "info" : "VariableDeclarationStatement[14905-14947]:VariableDeclarationStatement[14775-14817]"
  }, {
    "left" : "String fileName = tmpAry != null && tmpAry.length == 2 ? tmpAry[1]\n\t\t\t\t: null;",
    "right" : "String fileName = tmpAry != null && tmpAry.length == 2 ? tmpAry[1]\n\t\t\t\t: null;",
    "info" : "VariableDeclarationStatement[14950-15028]:VariableDeclarationStatement[14820-14898]"
  }, {
    "left" : "if (fileName == null)",
    "right" : "if (fileName == null)",
    "info" : "IfStatement[15031-15237]:IfStatement[14901-15107]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[15053-15148]:Block[14923-15018]"
  }, {
    "left" : "throw new RuntimeException(\"cache file is invalid format, file:\"\n\t\t\t\t\t+ cacheFileUrl);",
    "right" : "throw new RuntimeException(\"cache file is invalid format, file:\"\n\t\t\t\t\t+ cacheFileUrl);",
    "info" : "ThrowStatement[15058-15144]:ThrowStatement[14928-15014]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[15154-15237]:Block[15024-15107]"
  }, {
    "left" : "LOG.debug(\"cache file name is valid:\" + cacheFileUrl);",
    "right" : "LOG.debug(\"cache file name is valid:\" + cacheFileUrl);",
    "info" : "ExpressionStatement[15159-15213]:ExpressionStatement[15029-15083]"
  }, {
    "left" : "return fileName;",
    "right" : "return fileName;",
    "info" : "ReturnStatement[15217-15233]:ReturnStatement[15087-15103]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[15294-15633]:Block[15164-15503]"
  }, {
    "left" : "String[] tmpAry = cacheFileUrl.split(\"#\");",
    "right" : "String[] tmpAry = cacheFileUrl.split(\"#\");",
    "info" : "VariableDeclarationStatement[15298-15340]:VariableDeclarationStatement[15168-15210]"
  }, {
    "left" : "String fileName = tmpAry != null && tmpAry.length == 2 ? tmpAry[0]\n\t\t\t\t: null;",
    "right" : "String fileName = tmpAry != null && tmpAry.length == 2 ? tmpAry[0]\n\t\t\t\t: null;",
    "info" : "VariableDeclarationStatement[15343-15421]:VariableDeclarationStatement[15213-15291]"
  }, {
    "left" : "if (fileName == null)",
    "right" : "if (fileName == null)",
    "info" : "IfStatement[15424-15630]:IfStatement[15294-15500]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[15446-15541]:Block[15316-15411]"
  }, {
    "left" : "throw new RuntimeException(\"cache file is invalid format, file:\"\n\t\t\t\t\t+ cacheFileUrl);",
    "right" : "throw new RuntimeException(\"cache file is invalid format, file:\"\n\t\t\t\t\t+ cacheFileUrl);",
    "info" : "ThrowStatement[15451-15537]:ThrowStatement[15321-15407]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[15547-15630]:Block[15417-15500]"
  }, {
    "left" : "LOG.debug(\"cache file name is valid:\" + cacheFileUrl);",
    "right" : "LOG.debug(\"cache file name is valid:\" + cacheFileUrl);",
    "info" : "ExpressionStatement[15552-15606]:ExpressionStatement[15422-15476]"
  }, {
    "left" : "return fileName;",
    "right" : "return fileName;",
    "info" : "ReturnStatement[15610-15626]:ReturnStatement[15480-15496]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[15774-16157]:Block[15644-16027]"
  }, {
    "left" : "SparkCompiler sparkCompiler = new SparkCompiler(physicalPlan,\n\t\t\t\tpigContext);",
    "right" : "SparkCompiler sparkCompiler = new SparkCompiler(physicalPlan,\n\t\t\t\tpigContext);",
    "info" : "VariableDeclarationStatement[15778-15856]:VariableDeclarationStatement[15648-15726]"
  }, {
    "left" : "sparkCompiler.compile();",
    "right" : "sparkCompiler.compile();",
    "info" : "ExpressionStatement[15859-15883]:ExpressionStatement[15729-15753]"
  }, {
    "left" : "SparkOperPlan sparkPlan = sparkCompiler.getSparkPlan();",
    "right" : "SparkOperPlan sparkPlan = sparkCompiler.getSparkPlan();",
    "info" : "VariableDeclarationStatement[15886-15941]:VariableDeclarationStatement[15756-15811]"
  }, {
    "left" : "SparkPOPackageAnnotator pkgAnnotator = new SparkPOPackageAnnotator(\n\t\t\t\tsparkPlan);",
    "right" : "SparkPOPackageAnnotator pkgAnnotator = new SparkPOPackageAnnotator(\n\t\t\t\tsparkPlan);",
    "info" : "VariableDeclarationStatement[15991-16074]:VariableDeclarationStatement[15861-15944]"
  }, {
    "left" : "pkgAnnotator.visit();",
    "right" : "pkgAnnotator.visit();",
    "info" : "ExpressionStatement[16077-16098]:ExpressionStatement[15947-15968]"
  }, {
    "left" : "optimize(pigContext, sparkPlan);",
    "right" : "optimize(pigContext, sparkPlan);",
    "info" : "ExpressionStatement[16102-16134]:ExpressionStatement[15972-16004]"
  }, {
    "left" : "return sparkPlan;",
    "right" : "return sparkPlan;",
    "info" : "ReturnStatement[16137-16154]:ReturnStatement[16007-16024]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[16234-17490]:Block[16104-17360]"
  }, {
    "left" : "if (sparkContext == null)",
    "right" : "if (sparkContext == null)",
    "info" : "IfStatement[16238-17487]:IfStatement[16108-17357]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[16264-17487]:Block[16134-17357]"
  }, {
    "left" : "String master = null;",
    "right" : "String master = null;",
    "info" : "VariableDeclarationStatement[16269-16290]:VariableDeclarationStatement[16139-16160]"
  }, {
    "left" : "if (pc.getExecType().isLocal())",
    "right" : "if (pc.getExecType().isLocal())",
    "info" : "IfStatement[16294-16527]:IfStatement[16164-16397]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[16326-16354]:Block[16196-16224]"
  }, {
    "left" : "master = \"local\";",
    "right" : "master = \"local\";",
    "info" : "ExpressionStatement[16332-16349]:ExpressionStatement[16202-16219]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[16360-16527]:Block[16230-16397]"
  }, {
    "left" : "master = System.getenv(\"SPARK_MASTER\");",
    "right" : "master = System.getenv(\"SPARK_MASTER\");",
    "info" : "ExpressionStatement[16366-16405]:ExpressionStatement[16236-16275]"
  }, {
    "left" : "if (master == null)",
    "right" : "if (master == null)",
    "info" : "IfStatement[16410-16522]:IfStatement[16280-16392]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[16430-16522]:Block[16300-16392]"
  }, {
    "left" : "LOG.info(\"SPARK_MASTER not specified, using \\\"local\\\"\");",
    "right" : "LOG.info(\"SPARK_MASTER not specified, using \\\"local\\\"\");",
    "info" : "ExpressionStatement[16437-16493]:ExpressionStatement[16307-16363]"
  }, {
    "left" : "master = \"local\";",
    "right" : "master = \"local\";",
    "info" : "ExpressionStatement[16499-16516]:ExpressionStatement[16369-16386]"
  }, {
    "left" : "String sparkHome = System.getenv(\"SPARK_HOME\");",
    "right" : "String sparkHome = System.getenv(\"SPARK_HOME\");",
    "info" : "VariableDeclarationStatement[16532-16579]:VariableDeclarationStatement[16402-16449]"
  }, {
    "left" : "String sparkJarsSetting = System.getenv(\"SPARK_JARS\");",
    "right" : "String sparkJarsSetting = System.getenv(\"SPARK_JARS\");",
    "info" : "VariableDeclarationStatement[16583-16637]:VariableDeclarationStatement[16453-16507]"
  }, {
    "left" : "String pigJar = System.getenv(\"SPARK_PIG_JAR\");",
    "right" : "String pigJar = System.getenv(\"SPARK_PIG_JAR\");",
    "info" : "VariableDeclarationStatement[16641-16688]:VariableDeclarationStatement[16511-16558]"
  }, {
    "left" : "String[] sparkJars = sparkJarsSetting == null ? new String[] {}\n\t\t\t\t\t: sparkJarsSetting.split(\",\");",
    "right" : "String[] sparkJars = sparkJarsSetting == null ? new String[] {}\n\t\t\t\t\t: sparkJarsSetting.split(\",\");",
    "info" : "VariableDeclarationStatement[16692-16791]:VariableDeclarationStatement[16562-16661]"
  }, {
    "left" : "List<String> jars = Lists.asList(pigJar, sparkJars);",
    "right" : "List<String> jars = Lists.asList(pigJar, sparkJars);",
    "info" : "VariableDeclarationStatement[16795-16847]:VariableDeclarationStatement[16665-16717]"
  }, {
    "left" : "if (!master.startsWith(\"local\") && !master.equals(\"yarn-client\"))",
    "right" : "if (!master.startsWith(\"local\") && !master.equals(\"yarn-client\"))",
    "info" : "IfStatement[16852-17184]:IfStatement[16722-17054]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[16918-17184]:Block[16788-17054]"
  }, {
    "left" : "if (sparkHome == null)",
    "right" : "if (sparkHome == null)",
    "info" : "IfStatement[17005-17179]:IfStatement[16875-17049]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[17028-17179]:Block[16898-17049]"
  }, {
    "left" : "System.err\n\t\t\t\t\t\t\t.println(\"You need to set SPARK_HOME to run on a Mesos cluster!\");",
    "right" : "System.err\n\t\t\t\t\t\t\t.println(\"You need to set SPARK_HOME to run on a Mesos cluster!\");",
    "info" : "ExpressionStatement[17035-17119]:ExpressionStatement[16905-16989]"
  }, {
    "left" : "throw new PigException(\"SPARK_HOME is not set\");",
    "right" : "throw new PigException(\"SPARK_HOME is not set\");",
    "info" : "ThrowStatement[17125-17173]:ThrowStatement[16995-17043]"
  }, {
    "left" : "sparkContext = new JavaSparkContext(master, \"PigOnSpark\", sparkHome,\n\t\t\t\t\tjars.toArray(new String[jars.size()]));",
    "right" : "sparkContext = new JavaSparkContext(master, \"PigOnSpark\", sparkHome,\n\t\t\t\t\tjars.toArray(new String[jars.size()]));",
    "info" : "ExpressionStatement[17189-17302]:ExpressionStatement[17059-17172]"
  }, {
    "left" : "sparkContext.sc().addSparkListener(new StatsReportListener());",
    "right" : "sparkContext.sc().addSparkListener(new StatsReportListener());",
    "info" : "ExpressionStatement[17306-17368]:ExpressionStatement[17176-17238]"
  }, {
    "left" : "sparkContext.sc().addSparkListener(new JobLogger());",
    "right" : "sparkContext.sc().addSparkListener(new JobLogger());",
    "info" : "ExpressionStatement[17372-17424]:ExpressionStatement[17242-17294]"
  }, {
    "left" : "sparkContext.sc().addSparkListener(jobMetricsListener);",
    "right" : "sparkContext.sc().addSparkListener(jobMetricsListener);",
    "info" : "ExpressionStatement[17428-17483]:ExpressionStatement[17298-17353]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[17592-17678]:Block[17462-17548]"
  }, {
    "left" : "if (sparkContext != null)",
    "right" : "if (sparkContext != null)",
    "info" : "IfStatement[17596-17675]:IfStatement[17466-17545]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[17622-17675]:Block[17492-17545]"
  }, {
    "left" : "sparkContext.stop();",
    "right" : "sparkContext.stop();",
    "info" : "ExpressionStatement[17627-17647]:ExpressionStatement[17497-17517]"
  }, {
    "left" : "sparkContext = null;",
    "right" : "sparkContext = null;",
    "info" : "ExpressionStatement[17651-17671]:ExpressionStatement[17521-17541]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[17892-18567]:Block[17762-18437]"
  }, {
    "left" : "Set<Integer> seenJobIDs = new HashSet<Integer>();",
    "right" : "Set<Integer> seenJobIDs = new HashSet<Integer>();",
    "info" : "VariableDeclarationStatement[17896-17945]:VariableDeclarationStatement[17766-17815]"
  }, {
    "left" : "if (sparkPlan == null)",
    "right" : "if (sparkPlan == null)",
    "info" : "IfStatement[17948-18029]:IfStatement[17818-17899]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[17971-18029]:Block[17841-17899]"
  }, {
    "left" : "throw new RuntimeException(\"SparkPlan is null.\");",
    "right" : "throw new RuntimeException(\"SparkPlan is null.\");",
    "info" : "ThrowStatement[17976-18025]:ThrowStatement[17846-17895]"
  }, {
    "left" : "List<SparkOperator> leaves = sparkPlan.getLeaves();",
    "right" : "List<SparkOperator> leaves = sparkPlan.getLeaves();",
    "info" : "VariableDeclarationStatement[18033-18084]:VariableDeclarationStatement[17903-17954]"
  }, {
    "left" : "Collections.sort(leaves);",
    "right" : "Collections.sort(leaves);",
    "info" : "ExpressionStatement[18087-18112]:ExpressionStatement[17957-17982]"
  }, {
    "left" : "Map<OperatorKey, RDD<Tuple>> sparkOpToRdds = new HashMap();",
    "right" : "Map<OperatorKey, RDD<Tuple>> sparkOpToRdds = new HashMap();",
    "info" : "VariableDeclarationStatement[18115-18174]:VariableDeclarationStatement[17985-18044]"
  }, {
    "left" : "if (LOG.isDebugEnabled())",
    "right" : "if (LOG.isDebugEnabled())",
    "info" : "IfStatement[18177-18282]:IfStatement[18047-18152]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[18203-18282]:Block[18073-18152]"
  }, {
    "left" : "LOG.debug(\"Converting \" + leaves.size() + \" Spark Operators to RDDs\");",
    "right" : "LOG.debug(\"Converting \" + leaves.size() + \" Spark Operators to RDDs\");",
    "info" : "ExpressionStatement[18208-18278]:ExpressionStatement[18078-18148]"
  }, {
    "left" : "for (SparkOperator leaf : leaves)",
    "right" : "for (SparkOperator leaf : leaves)",
    "info" : "EnhancedForStatement[18286-18564]:EnhancedForStatement[18156-18434]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[18320-18564]:Block[18190-18434]"
  }, {
    "left" : "new PhyPlanSetter(leaf.physicalPlan).visit();",
    "right" : "new PhyPlanSetter(leaf.physicalPlan).visit();",
    "info" : "ExpressionStatement[18325-18370]:ExpressionStatement[18195-18240]"
  }, {
    "left" : "Map<OperatorKey, RDD<Tuple>> physicalOpToRdds = new HashMap();",
    "right" : "Map<OperatorKey, RDD<Tuple>> physicalOpToRdds = new HashMap();",
    "info" : "VariableDeclarationStatement[18374-18436]:VariableDeclarationStatement[18244-18306]"
  }, {
    "left" : "sparkOperToRDD(sparkPlan, leaf, sparkOpToRdds,\n\t\t\t\t\tphysicalOpToRdds, convertMap, seenJobIDs, sparkStats,\n\t\t\t\t\tjobConf);",
    "right" : "sparkOperToRDD(sparkPlan, leaf, sparkOpToRdds,\n\t\t\t\t\tphysicalOpToRdds, convertMap, seenJobIDs, sparkStats,\n\t\t\t\t\tjobConf);",
    "info" : "ExpressionStatement[18440-18560]:ExpressionStatement[18310-18430]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[18662-19077]:Block[18532-18947]"
  }, {
    "left" : "for (String udf : leaf.UDFs)",
    "right" : "for (String udf : leaf.UDFs)",
    "info" : "EnhancedForStatement[18673-19071]:EnhancedForStatement[18543-18941]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[18702-19071]:Block[18572-18941]"
  }, {
    "left" : "Class clazz = pigContext.getClassForAlias(udf);",
    "right" : "Class clazz = pigContext.getClassForAlias(udf);",
    "info" : "VariableDeclarationStatement[18716-18763]:VariableDeclarationStatement[18586-18633]"
  }, {
    "left" : "if (clazz != null)",
    "right" : "if (clazz != null)",
    "info" : "IfStatement[18776-19061]:IfStatement[18646-18931]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[18795-19061]:Block[18665-18931]"
  }, {
    "left" : "String jar = JarManager.findContainingJar(clazz);",
    "right" : "String jar = JarManager.findContainingJar(clazz);",
    "info" : "VariableDeclarationStatement[18813-18862]:VariableDeclarationStatement[18683-18732]"
  }, {
    "left" : "if( jar != null)",
    "right" : "if( jar != null)",
    "info" : "IfStatement[18879-19047]:IfStatement[18749-18917]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[18896-19047]:Block[18766-18917]"
  }, {
    "left" : "File jarFile = new File(jar);",
    "right" : "File jarFile = new File(jar);",
    "info" : "VariableDeclarationStatement[18918-18947]:VariableDeclarationStatement[18788-18817]"
  }, {
    "left" : "addJarToSparkJobWorkingDirectory(jarFile, jarFile.getName());",
    "right" : "addJarToSparkJobWorkingDirectory(jarFile, jarFile.getName());",
    "info" : "ExpressionStatement[18968-19029]:ExpressionStatement[18838-18899]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[19441-21885]:Block[19311-21755]"
  }, {
    "left" : "addUDFJarsToSparkJobWorkingDirectory(sparkOperator);",
    "right" : "addUDFJarsToSparkJobWorkingDirectory(sparkOperator);",
    "info" : "ExpressionStatement[19451-19503]:ExpressionStatement[19321-19373]"
  }, {
    "left" : "List<SparkOperator> predecessors = sparkPlan\n\t\t\t\t.getPredecessors(sparkOperator);",
    "right" : "List<SparkOperator> predecessors = sparkPlan\n\t\t\t\t.getPredecessors(sparkOperator);",
    "info" : "VariableDeclarationStatement[19506-19587]:VariableDeclarationStatement[19376-19457]"
  }, {
    "left" : "List<RDD<Tuple>> predecessorRDDs = Lists.newArrayList();",
    "right" : "List<RDD<Tuple>> predecessorRDDs = Lists.newArrayList();",
    "info" : "VariableDeclarationStatement[19590-19646]:VariableDeclarationStatement[19460-19516]"
  }, {
    "left" : "if (predecessors != null)",
    "right" : "if (predecessors != null)",
    "info" : "IfStatement[19649-19982]:IfStatement[19519-19852]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[19675-19982]:Block[19545-19852]"
  }, {
    "left" : "for (SparkOperator pred : predecessors)",
    "right" : "for (SparkOperator pred : predecessors)",
    "info" : "EnhancedForStatement[19680-19978]:EnhancedForStatement[19550-19848]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[19720-19978]:Block[19590-19848]"
  }, {
    "left" : "if (sparkOpRdds.get(pred.getOperatorKey()) == null)",
    "right" : "if (sparkOpRdds.get(pred.getOperatorKey()) == null)",
    "info" : "IfStatement[19726-19908]:IfStatement[19596-19778]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[19778-19908]:Block[19648-19778]"
  }, {
    "left" : "sparkOperToRDD(sparkPlan, pred, sparkOpRdds,\n\t\t\t\t\t\t\tphysicalOpRdds, convertMap, seenJobIDs, sparkStats,\n\t\t\t\t\t\t\tconf);",
    "right" : "sparkOperToRDD(sparkPlan, pred, sparkOpRdds,\n\t\t\t\t\t\t\tphysicalOpRdds, convertMap, seenJobIDs, sparkStats,\n\t\t\t\t\t\t\tconf);",
    "info" : "ExpressionStatement[19785-19902]:ExpressionStatement[19655-19772]"
  }, {
    "left" : "predecessorRDDs.add(sparkOpRdds.get(pred.getOperatorKey()));",
    "right" : "predecessorRDDs.add(sparkOpRdds.get(pred.getOperatorKey()));",
    "info" : "ExpressionStatement[19913-19973]:ExpressionStatement[19783-19843]"
  }, {
    "left" : "List<PhysicalOperator> leafPOs = sparkOperator.physicalPlan.getLeaves();",
    "right" : "List<PhysicalOperator> leafPOs = sparkOperator.physicalPlan.getLeaves();",
    "info" : "VariableDeclarationStatement[19986-20058]:VariableDeclarationStatement[19856-19928]"
  }, {
    "left" : "boolean isFail = false;",
    "right" : "boolean isFail = false;",
    "info" : "VariableDeclarationStatement[20061-20084]:VariableDeclarationStatement[19931-19954]"
  }, {
    "left" : "Exception exception = null;",
    "right" : "Exception exception = null;",
    "info" : "VariableDeclarationStatement[20087-20114]:VariableDeclarationStatement[19957-19984]"
  }, {
    "left" : "if (leafPOs != null && leafPOs.size() != 1)",
    "right" : "if (leafPOs != null && leafPOs.size() != 1)",
    "info" : "IfStatement[20117-20501]:IfStatement[19987-20371]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[20161-20501]:Block[20031-20371]"
  }, {
    "left" : "throw new IllegalArgumentException(\n\t\t\t\t\tString.format(\n\t\t\t\t\t\t\t\"sparkOperator \"\n\t\t\t\t\t\t\t\t\t+ \".physicalPlan should have 1 leaf, but  sparkOperator\"\n\t\t\t\t\t\t\t\t\t+ \".physicalPlan.getLeaves():{} not equals 1, sparkOperator\"\n\t\t\t\t\t\t\t\t\t+ \"sparkOperator:{}\",\n\t\t\t\t\t\t\tsparkOperator.physicalPlan.getLeaves().size(),\n\t\t\t\t\t\t\tsparkOperator.name()));",
    "right" : "throw new IllegalArgumentException(\n\t\t\t\t\tString.format(\n\t\t\t\t\t\t\t\"sparkOperator \"\n\t\t\t\t\t\t\t\t\t+ \".physicalPlan should have 1 leaf, but  sparkOperator\"\n\t\t\t\t\t\t\t\t\t+ \".physicalPlan.getLeaves():{} not equals 1, sparkOperator\"\n\t\t\t\t\t\t\t\t\t+ \"sparkOperator:{}\",\n\t\t\t\t\t\t\tsparkOperator.physicalPlan.getLeaves().size(),\n\t\t\t\t\t\t\tsparkOperator.name()));",
    "info" : "ThrowStatement[20166-20497]:ThrowStatement[20036-20367]"
  }, {
    "left" : "PhysicalOperator leafPO = leafPOs.get(0);",
    "right" : "PhysicalOperator leafPO = leafPOs.get(0);",
    "info" : "VariableDeclarationStatement[20505-20546]:VariableDeclarationStatement[20375-20416]"
  }, {
    "left" : "try{...}",
    "right" : "try{...}",
    "info" : "TryStatement[20549-20959]:TryStatement[20419-20829]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[20553-20764]:Block[20423-20634]"
  }, {
    "left" : "physicalToRDD(sparkOperator.physicalPlan, leafPO, physicalOpRdds,\n\t\t\t\t\tpredecessorRDDs, convertMap);",
    "right" : "physicalToRDD(sparkOperator.physicalPlan, leafPO, physicalOpRdds,\n\t\t\t\t\tpredecessorRDDs, convertMap);",
    "info" : "ExpressionStatement[20558-20658]:ExpressionStatement[20428-20528]"
  }, {
    "left" : "sparkOpRdds.put(sparkOperator.getOperatorKey(),\n\t\t\t\t\tphysicalOpRdds.get(leafPO.getOperatorKey()));",
    "right" : "sparkOpRdds.put(sparkOperator.getOperatorKey(),\n\t\t\t\t\tphysicalOpRdds.get(leafPO.getOperatorKey()));",
    "info" : "ExpressionStatement[20662-20760]:ExpressionStatement[20532-20630]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[20784-20959]:Block[20654-20829]"
  }, {
    "left" : "if( e instanceof  SparkException)",
    "right" : "if( e instanceof  SparkException)",
    "info" : "IfStatement[20789-20919]:IfStatement[20659-20789]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[20823-20919]:Block[20693-20789]"
  }, {
    "left" : "LOG.info(\"throw SparkException, error founds when running \" +\n\t\t\t\t\t\t\"rdds in spark\");",
    "right" : "LOG.info(\"throw SparkException, error founds when running \" +\n\t\t\t\t\t\t\"rdds in spark\");",
    "info" : "ExpressionStatement[20829-20914]:ExpressionStatement[20699-20784]"
  }, {
    "left" : "exception = e;",
    "right" : "exception = e;",
    "info" : "ExpressionStatement[20923-20937]:ExpressionStatement[20793-20807]"
  }, {
    "left" : "isFail = true;",
    "right" : "isFail = true;",
    "info" : "ExpressionStatement[20941-20955]:ExpressionStatement[20811-20825]"
  }, {
    "left" : "List<POStore> poStores = PlanHelper.getPhysicalOperators(\n\t\t\t\tsparkOperator.physicalPlan, POStore.class);",
    "right" : "List<POStore> poStores = PlanHelper.getPhysicalOperators(\n\t\t\t\tsparkOperator.physicalPlan, POStore.class);",
    "info" : "VariableDeclarationStatement[20963-21068]:VariableDeclarationStatement[20833-20938]"
  }, {
    "left" : "if (poStores != null && poStores.size() == 1)",
    "right" : "if (poStores != null && poStores.size() == 1)",
    "info" : "IfStatement[21071-21882]:IfStatement[20941-21752]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[21117-21651]:Block[20987-21521]"
  }, {
    "left" : "POStore poStore = poStores.get(0);",
    "right" : "POStore poStore = poStores.get(0);",
    "info" : "VariableDeclarationStatement[21124-21158]:VariableDeclarationStatement[20994-21028]"
  }, {
    "left" : "if (!isFail)",
    "right" : "if (!isFail)",
    "info" : "IfStatement[21171-21641]:IfStatement[21041-21511]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[21184-21426]:Block[21054-21296]"
  }, {
    "left" : "for (int jobID : getJobIDs(seenJobIDs))",
    "right" : "for (int jobID : getJobIDs(seenJobIDs))",
    "info" : "EnhancedForStatement[21202-21412]:EnhancedForStatement[21072-21282]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[21242-21412]:Block[21112-21282]"
  }, {
    "left" : "SparkStatsUtil.waitForJobAddStats(jobID, poStore,\n                            jobMetricsListener, sparkContext, sparkStats, conf);",
    "right" : "SparkStatsUtil.waitForJobAddStats(jobID, poStore,\n                            jobMetricsListener, sparkContext, sparkStats, conf);",
    "info" : "ExpressionStatement[21264-21394]:ExpressionStatement[21134-21264]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[21432-21641]:Block[21302-21511]"
  }, {
    "left" : "String failJobID = sparkOperator.name().concat(\"_fail\");",
    "right" : "String failJobID = sparkOperator.name().concat(\"_fail\");",
    "info" : "VariableDeclarationStatement[21450-21506]:VariableDeclarationStatement[21320-21376]"
  }, {
    "left" : "SparkStatsUtil.addFailJobStats(failJobID, poStore, sparkStats,\n                        conf, exception);",
    "right" : "SparkStatsUtil.addFailJobStats(failJobID, poStore, sparkStats,\n                        conf, exception);",
    "info" : "ExpressionStatement[21523-21627]:ExpressionStatement[21393-21497]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[21657-21882]:Block[21527-21752]"
  }, {
    "left" : "LOG.info(String\n\t\t\t\t\t.format(String.format(\"sparkOperator:{} does not have POStore or\" +\n\t\t\t\t\t\t\t\t\t\" sparkOperator has more than 1 POStore. {} is the size of POStore.\"),\n\t\t\t\t\t\t\tsparkOperator.name(), poStores.size()));",
    "right" : "LOG.info(String\n\t\t\t\t\t.format(String.format(\"sparkOperator:{} does not have POStore or\" +\n\t\t\t\t\t\t\t\t\t\" sparkOperator has more than 1 POStore. {} is the size of POStore.\"),\n\t\t\t\t\t\t\tsparkOperator.name(), poStores.size()));",
    "info" : "ExpressionStatement[21662-21878]:ExpressionStatement[21532-21748]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[22144-23478]:Block[22014-23348]"
  }, {
    "left" : "RDD<Tuple> nextRDD = null;",
    "right" : "RDD<Tuple> nextRDD = null;",
    "info" : "VariableDeclarationStatement[22154-22180]:VariableDeclarationStatement[22024-22050]"
  }, {
    "left" : "List<PhysicalOperator> predecessors = plan\n                .getPredecessors(physicalOperator);",
    "right" : "List<PhysicalOperator> predecessors = plan\n                .getPredecessors(physicalOperator);",
    "info" : "VariableDeclarationStatement[22189-22283]:VariableDeclarationStatement[22059-22153]"
  }, {
    "left" : "if (predecessors != null && predecessors.size() > 1)",
    "right" : "if (predecessors != null && predecessors.size() > 1)",
    "info" : "IfStatement[22292-22400]:IfStatement[22162-22270]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[22345-22400]:Block[22215-22270]"
  }, {
    "left" : "Collections.sort(predecessors);",
    "right" : "Collections.sort(predecessors);",
    "info" : "ExpressionStatement[22359-22390]:ExpressionStatement[22229-22260]"
  }, {
    "left" : "List<RDD<Tuple>> predecessorRdds = Lists.newArrayList();",
    "right" : "List<RDD<Tuple>> predecessorRdds = Lists.newArrayList();",
    "info" : "VariableDeclarationStatement[22410-22466]:VariableDeclarationStatement[22280-22336]"
  }, {
    "left" : "if (predecessors != null)",
    "right" : "if (predecessors != null)",
    "info" : "IfStatement[22469-22863]:IfStatement[22339-22733]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[22495-22712]:Block[22365-22582]"
  }, {
    "left" : "for (PhysicalOperator predecessor : predecessors)",
    "right" : "for (PhysicalOperator predecessor : predecessors)",
    "info" : "EnhancedForStatement[22500-22707]:EnhancedForStatement[22370-22577]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[22550-22707]:Block[22420-22577]"
  }, {
    "left" : "physicalToRDD(plan, predecessor, rdds, rddsFromPredeSparkOper,\n\t\t\t\t\t\tconvertMap);",
    "right" : "physicalToRDD(plan, predecessor, rdds, rddsFromPredeSparkOper,\n\t\t\t\t\t\tconvertMap);",
    "info" : "ExpressionStatement[22556-22637]:ExpressionStatement[22426-22507]"
  }, {
    "left" : "predecessorRdds.add(rdds.get(predecessor.getOperatorKey()));",
    "right" : "predecessorRdds.add(rdds.get(predecessor.getOperatorKey()));",
    "info" : "ExpressionStatement[22642-22702]:ExpressionStatement[22512-22572]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[22718-22863]:Block[22588-22733]"
  }, {
    "left" : "if (rddsFromPredeSparkOper != null\n\t\t\t\t\t&& rddsFromPredeSparkOper.size() > 0)",
    "right" : "if (rddsFromPredeSparkOper != null\n\t\t\t\t\t&& rddsFromPredeSparkOper.size() > 0)",
    "info" : "IfStatement[22723-22859]:IfStatement[22593-22729]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[22801-22859]:Block[22671-22729]"
  }, {
    "left" : "predecessorRdds.addAll(rddsFromPredeSparkOper);",
    "right" : "predecessorRdds.addAll(rddsFromPredeSparkOper);",
    "info" : "ExpressionStatement[22807-22854]:ExpressionStatement[22677-22724]"
  }, {
    "left" : "RDDConverter converter = convertMap.get(physicalOperator.getClass());",
    "right" : "RDDConverter converter = convertMap.get(physicalOperator.getClass());",
    "info" : "VariableDeclarationStatement[22867-22936]:VariableDeclarationStatement[22737-22806]"
  }, {
    "left" : "if (converter == null)",
    "right" : "if (converter == null)",
    "info" : "IfStatement[22939-23084]:IfStatement[22809-22954]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[22962-23084]:Block[22832-22954]"
  }, {
    "left" : "throw new IllegalArgumentException(\n\t\t\t\t\t\"Pig on Spark does not support Physical Operator: \" + physicalOperator);",
    "right" : "throw new IllegalArgumentException(\n\t\t\t\t\t\"Pig on Spark does not support Physical Operator: \" + physicalOperator);",
    "info" : "ThrowStatement[22967-23080]:ThrowStatement[22837-22950]"
  }, {
    "left" : "LOG.info(\"Converting operator \"\n\t\t\t\t+ physicalOperator.getClass().getSimpleName() + \" \"\n\t\t\t\t+ physicalOperator);",
    "right" : "LOG.info(\"Converting operator \"\n\t\t\t\t+ physicalOperator.getClass().getSimpleName() + \" \"\n\t\t\t\t+ physicalOperator);",
    "info" : "ExpressionStatement[23088-23200]:ExpressionStatement[22958-23070]"
  }, {
    "left" : "nextRDD = converter.convert(predecessorRdds, physicalOperator);",
    "right" : "nextRDD = converter.convert(predecessorRdds, physicalOperator);",
    "info" : "ExpressionStatement[23203-23266]:ExpressionStatement[23073-23136]"
  }, {
    "left" : "if (nextRDD == null)",
    "right" : "if (nextRDD == null)",
    "info" : "IfStatement[23270-23418]:IfStatement[23140-23288]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[23291-23418]:Block[23161-23288]"
  }, {
    "left" : "throw new IllegalArgumentException(\n\t\t\t\t\t\"RDD should not be null after PhysicalOperator: \"\n\t\t\t\t\t\t\t+ physicalOperator);",
    "right" : "throw new IllegalArgumentException(\n\t\t\t\t\t\"RDD should not be null after PhysicalOperator: \"\n\t\t\t\t\t\t\t+ physicalOperator);",
    "info" : "ThrowStatement[23296-23414]:ThrowStatement[23166-23284]"
  }, {
    "left" : "rdds.put(physicalOperator.getOperatorKey(), nextRDD);",
    "right" : "rdds.put(physicalOperator.getOperatorKey(), nextRDD);",
    "info" : "ExpressionStatement[23422-23475]:ExpressionStatement[23292-23345]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[23614-23706]:Block[23484-23576]"
  }, {
    "left" : "SparkOperPlan sparkPlan = compile(pp, pc);",
    "right" : "SparkOperPlan sparkPlan = compile(pp, pc);",
    "info" : "VariableDeclarationStatement[23618-23660]:VariableDeclarationStatement[23488-23530]"
  }, {
    "left" : "explain(sparkPlan, ps, format, verbose);",
    "right" : "explain(sparkPlan, ps, format, verbose);",
    "info" : "ExpressionStatement[23663-23703]:ExpressionStatement[23533-23573]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[23831-24661]:Block[23701-24531]"
  }, {
    "left" : "Map<OperatorKey, SparkOperator> allOperKeys = sparkPlan.getKeys();",
    "right" : "Map<OperatorKey, SparkOperator> allOperKeys = sparkPlan.getKeys();",
    "info" : "VariableDeclarationStatement[23835-23901]:VariableDeclarationStatement[23705-23771]"
  }, {
    "left" : "List<OperatorKey> operKeyList = new ArrayList(allOperKeys.keySet());",
    "right" : "List<OperatorKey> operKeyList = new ArrayList(allOperKeys.keySet());",
    "info" : "VariableDeclarationStatement[23904-23972]:VariableDeclarationStatement[23774-23842]"
  }, {
    "left" : "Collections.sort(operKeyList);",
    "right" : "Collections.sort(operKeyList);",
    "info" : "ExpressionStatement[23975-24005]:ExpressionStatement[23845-23875]"
  }, {
    "left" : "for (OperatorKey operatorKey : operKeyList)",
    "right" : "for (OperatorKey operatorKey : operKeyList)",
    "info" : "EnhancedForStatement[24008-24377]:EnhancedForStatement[23878-24247]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[24052-24377]:Block[23922-24247]"
  }, {
    "left" : "SparkOperator op = sparkPlan.getOperator(operatorKey);",
    "right" : "SparkOperator op = sparkPlan.getOperator(operatorKey);",
    "info" : "VariableDeclarationStatement[24057-24111]:VariableDeclarationStatement[23927-23981]"
  }, {
    "left" : "ps.print(op.getOperatorKey());",
    "right" : "ps.print(op.getOperatorKey());",
    "info" : "ExpressionStatement[24115-24145]:ExpressionStatement[23985-24015]"
  }, {
    "left" : "List<SparkOperator> successors = sparkPlan.getSuccessors(op);",
    "right" : "List<SparkOperator> successors = sparkPlan.getSuccessors(op);",
    "info" : "VariableDeclarationStatement[24149-24210]:VariableDeclarationStatement[24019-24080]"
  }, {
    "left" : "if (successors != null)",
    "right" : "if (successors != null)",
    "info" : "IfStatement[24214-24356]:IfStatement[24084-24226]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[24238-24356]:Block[24108-24226]"
  }, {
    "left" : "ps.print(\"->\");",
    "right" : "ps.print(\"->\");",
    "info" : "ExpressionStatement[24244-24259]:ExpressionStatement[24114-24129]"
  }, {
    "left" : "for (SparkOperator suc : successors)",
    "right" : "for (SparkOperator suc : successors)",
    "info" : "EnhancedForStatement[24264-24351]:EnhancedForStatement[24134-24221]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[24301-24351]:Block[24171-24221]"
  }, {
    "left" : "ps.print(suc.getOperatorKey() + \" \");",
    "right" : "ps.print(suc.getOperatorKey() + \" \");",
    "info" : "ExpressionStatement[24308-24345]:ExpressionStatement[24178-24215]"
  }, {
    "left" : "ps.println();",
    "right" : "ps.println();",
    "info" : "ExpressionStatement[24360-24373]:ExpressionStatement[24230-24243]"
  }, {
    "left" : "if (format.equals(\"text\"))",
    "right" : "if (format.equals(\"text\"))",
    "info" : "IfStatement[24381-24658]:IfStatement[24251-24528]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[24408-24524]:Block[24278-24394]"
  }, {
    "left" : "SparkPrinter printer = new SparkPrinter(ps, sparkPlan);",
    "right" : "SparkPrinter printer = new SparkPrinter(ps, sparkPlan);",
    "info" : "VariableDeclarationStatement[24413-24468]:VariableDeclarationStatement[24283-24338]"
  }, {
    "left" : "printer.setVerbose(verbose);",
    "right" : "printer.setVerbose(verbose);",
    "info" : "ExpressionStatement[24472-24500]:ExpressionStatement[24342-24370]"
  }, {
    "left" : "printer.visit();",
    "right" : "printer.visit();",
    "info" : "ExpressionStatement[24504-24520]:ExpressionStatement[24374-24390]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[24530-24658]:Block[24400-24528]"
  }, {
    "left" : "throw new IOException(\n\t\t\t\t\t\"Non-text output of explain is not supported.\");",
    "right" : "throw new IOException(\n\t\t\t\t\t\"Non-text output of explain is not supported.\");",
    "info" : "ThrowStatement[24578-24654]:ThrowStatement[24448-24524]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[24718-24760]:Block[24588-24630]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[24855-24897]:Block[24725-24767]"
  }, {
    "left" : "{}",
    "right" : "{}",
    "info" : "Block[25385-25567]:Block[25209-25391]"
  }, {
    "left" : "String udfImportList = Joiner.on(\",\").join(PigContext.getPackageImportList());",
    "right" : "String udfImportList = Joiner.on(\",\").join(PigContext.getPackageImportList());",
    "info" : "VariableDeclarationStatement[25395-25473]:VariableDeclarationStatement[25219-25297]"
  }, {
    "left" : "pigContext.getProperties().setProperty(\"spark.udf.import.list\", udfImportList);",
    "right" : "pigContext.getProperties().setProperty(\"spark.udf.import.list\", udfImportList);",
    "info" : "ExpressionStatement[25482-25561]:ExpressionStatement[25306-25385]"
  } ]
}